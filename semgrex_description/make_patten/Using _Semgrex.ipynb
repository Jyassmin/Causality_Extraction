{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semgrex를 활용한 인과추출\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Semgrex Example(인과추출은X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stanfordNLP 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "input text\n",
      "\n",
      "Chris Manning is a nice person. Chris wrote a simple sentence. He also gives oranges to people.\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-765bfddbfc584c05.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "[{'length': 0}, {'0': {'text': 'wrote', 'begin': 1, 'end': 2, '$subject': {'text': 'Chris', 'begin': 0, 'end': 1}, '$object': {'text': 'sentence', 'begin': 4, 'end': 5}}, 'length': 1}, {'length': 0}]\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "# example text\n",
    "print('---')\n",
    "print('input text')\n",
    "print('')\n",
    "\n",
    "text = \"Chris Manning is a nice person. Chris wrote a simple sentence. He also gives oranges to people.\"\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "    # Use tokensregex patterns to find who wrote a sentence.\n",
    "    pattern = '([ner: PERSON]+) /wrote/ /an?/ []{0,3} /sentence|article/'\n",
    "    matches = client.tokensregex(text, pattern)\n",
    "    # sentences contains a list with matches for each sentence.\n",
    "    \n",
    "    assert len(matches[\"sentences\"]) == 3\n",
    "    # length tells you whether or not there are any matches in this\n",
    "#\"length\"는 여기에 일치하는 항목이 있는지 여부를 알려줌\n",
    "    assert matches[\"sentences\"][1][\"length\"] == 1\n",
    "    # You can access matches like most regex groups.\n",
    "    matches[\"sentences\"][1][\"0\"][\"text\"] == \"Chris wrote a simple sentence\"\n",
    "    matches[\"sentences\"][1][\"0\"][\"1\"][\"text\"] == \"Chris\"\n",
    "\n",
    "    # Use semgrex patterns to directly find who wrote what.\n",
    "    pattern = '{word:wrote} >nsubj {}=subject >dobj {}=object'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches[\"sentences\"])\n",
    "    print(len(matches[\"sentences\"]))\n",
    "    print(matches[\"sentences\"][1][\"length\"])    \n",
    "\n",
    "    # sentences contains a list with matches for each sentence.\n",
    "    assert len(matches[\"sentences\"]) == 3\n",
    "    # length tells you whether or not there are any matches in this\n",
    "    assert matches[\"sentences\"][1][\"length\"] == 1\n",
    "    # You can access matches like most regex groups.\n",
    "    matches[\"sentences\"][1][\"0\"][\"text\"] == \"wrote\"\n",
    "    matches[\"sentences\"][1][\"0\"][\"$subject\"][\"text\"] == \"Chris\"\n",
    "    matches[\"sentences\"][1][\"0\"][\"$object\"][\"text\"] == \"sentence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanza 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordnlp.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-6aacae97583446a3.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse\n",
      "----------------------------------------------------------------------\n",
      "{'sentences': [{'length': 0}, {'length': 0}, {'length': 0}]}\n"
     ]
    }
   ],
   "source": [
    "text = \"Chris Manning is a nice person. Chris wrote a simple sentence. He also gives oranges to people.\"\n",
    "with CoreNLPClient(\n",
    "        annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse'],\n",
    "        timeout=30000,\n",
    "        memory='16G') as client:\n",
    "\n",
    "    # Use semgrex patterns to directly find who wrote what.\n",
    "    pattern = '{word:wrote} >nsubj {}=subject >obj {}=object'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(matches)\n",
    "#     # sentences contains a list with matches for each sentence.\n",
    "#     print(len(matches[\"sentences\"])) # prints: 3\n",
    "#     # length tells you whether or not there are any matches in this\n",
    "#     print(matches[\"sentences\"][1][\"length\"]) # prints: 1\n",
    "#     # You can access matches like most regex groups.\n",
    "#     print(matches[\"sentences\"][1][\"0\"][\"text\"]) # prints: \"wrote\"\n",
    "#     print(matches[\"sentences\"][1][\"0\"][\"$subject\"][\"text\"]) # prints: \"Chris\"\n",
    "#     print(matches[\"sentences\"][1][\"0\"][\"$object\"][\"text\"]) # prints: \"sentence\"\n",
    "\n",
    "#     # Tregex example\n",
    "#     pattern = 'NP'\n",
    "#     matches = client.tregex(text, pattern)\n",
    "#     # You can access matches similarly\n",
    "#     print(matches['sentences'][1]['1']['match']) # prints: \"(NP (DT a) (JJ simple) (NN sentence))\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "input text\n",
      "\n",
      "Over thinking can increase anxiety and cause insomnia.\n",
      "---\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-58eed0f0e0384693.props -preload tokenize,ssplit,pos,lemma,ner,depparse,coref\n",
      "------------------------\n",
      "[{'0': {'text': 'thinking', 'begin': 1, 'end': 2, '$cause': {'text': 'insomnia', 'begin': 7, 'end': 8}, '$subj': {'text': 'thinking', 'begin': 1, 'end': 2}, '$target': {'text': 'cause', 'begin': 6, 'end': 7}}, 'length': 1}]\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "# example text\n",
    "print('---')\n",
    "print('input text')\n",
    "print('')\n",
    "text = \"Over thinking can increase anxiety and cause insomnia.\"\n",
    "print(text)\n",
    "# set up the client\n",
    "print('---')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner','depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "# sentence = ann.sentence[0] #문장 3개 중 (첫)번째 문장\n",
    "#print(sentence.basicDependencies) #의존성구문 분석\n",
    "#print(sentence.token[5]) #첫 문장 안의 (첫)단어를 끊어 분석(token)\n",
    "#print(sentence.token[0].pos) #한 토큰 분석한 결과 중 pos만 따로 확인\n",
    "#---\n",
    "#print(sentence.ner) #주어 추출\n",
    "#print(sentence.mentions[0]) # 주어 추출2?\n",
    "#print(ann.corefChain) #뭔지모르겠음\n",
    "\n",
    "#pattern = '([ner: PERSON]+) /wrote/ /an?/ []{0,3} /sentence|article/'\n",
    "#matches = client.tokensregex(text, pattern)\n",
    "#assert len(matches[\"sentences\"]) == 3\n",
    "#print(matches)\n",
    "#assert matches[\"sentences\"][1][\"length\"] == 1\n",
    "#matches[\"sentences\"][1][\"0\"][\"text\"] == \"Chris wrote a simple sentence\"\n",
    "#matches[\"sentences\"][1][\"0\"][\"1\"][\"text\"] == \"Chris\"\n",
    "\n",
    "    pattern = '{} = subj < csubj ({word:/cause/} = target >dobj {} = cause)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    #print(matches[\"sentences\"][0][\"0\"])\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "input text\n",
      "\n",
      "Over thinking can increase anxiety and cause insomnia.\n",
      "---\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-c58e0524599347b0.props -preload tokenize,ssplit,pos,lemma,ner,depparse,coref\n",
      "------------------------\n",
      "[{'0': {'text': 'thinking', 'begin': 1, 'end': 2, '$cause': {'text': 'insomnia', 'begin': 7, 'end': 8}, '$subj': {'text': 'thinking', 'begin': 1, 'end': 2}, '$target': {'text': 'cause', 'begin': 6, 'end': 7}}, 'length': 1}]\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "# example text\n",
    "print('---')\n",
    "print('input text')\n",
    "print('')\n",
    "text = \"Over thinking can increase anxiety and cause insomnia.\"\n",
    "print(text)\n",
    "# set up the client\n",
    "print('---')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner','depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "# sentence = ann.sentence[0] #문장 3개 중 (첫)번째 문장\n",
    "#print(sentence.basicDependencies) #의존성구문 분석\n",
    "#print(sentence.token[5]) #첫 문장 안의 (첫)단어를 끊어 분석(token)\n",
    "#print(sentence.token[0].pos) #한 토큰 분석한 결과 중 pos만 따로 확인\n",
    "#---\n",
    "#print(sentence.ner) #주어 추출\n",
    "#print(sentence.mentions[0]) # 주어 추출2?\n",
    "#print(ann.corefChain) #뭔지모르겠음\n",
    "\n",
    "#pattern = '([ner: PERSON]+) /wrote/ /an?/ []{0,3} /sentence|article/'\n",
    "#matches = client.tokensregex(text, pattern)\n",
    "#assert len(matches[\"sentences\"]) == 3\n",
    "#print(matches)\n",
    "#assert matches[\"sentences\"][1][\"length\"] == 1\n",
    "#matches[\"sentences\"][1][\"0\"][\"text\"] == \"Chris wrote a simple sentence\"\n",
    "#matches[\"sentences\"][1][\"0\"][\"1\"][\"text\"] == \"Chris\"\n",
    "\n",
    "    pattern = '{} = subj < csubj ({word:/cause/} = target >dobj {} = cause)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    #print(matches[\"sentences\"][0][\"0\"])\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semgrex 인과추출 Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jones et al demonstrated that the presence of sarcopenia in copd affect the response to pr and in some patients pr might lead to a resolution of sarcopenia\n",
      "---\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 150000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-7bcac9226c9b464b.props -preload tokenize,ssplit,pos,lemma,ner,depparse,coref\n",
      "------------------------\n",
      "{'sentences': [{'0': {'text': 'presence', 'begin': 6, 'end': 7, '$effect': {'text': 'response', 'begin': 13, 'end': 14}, '$cause': {'text': 'presence', 'begin': 6, 'end': 7}, '$trigger': {'text': 'affect', 'begin': 11, 'end': 12}}, 'length': 1}]}\n",
      "False\n",
      "------------------------\n",
      "presence\n",
      "affect\n",
      "response\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "# text = \"Stress causes insomnia.\"\n",
    "# text = \"Missing someone causes insomnia.\"  #Missing someone으로 추출이 안되네?\n",
    "# text = \"Money only causes stress and conflict.\"\n",
    "# text = \"Cell phone radiation can cause insomnia\"\n",
    "# text = \"My neck just made my headache 100x worse.\"  # >dobj로 하면 추출 안됨 패턴 바꿔야함\n",
    "# text = \"stress doesn't cause depression\"\n",
    "text = \"jones et al demonstrated that the presence of sarcopenia in copd affect the response to pr and in some patients pr might lead to a resolution of sarcopenia\"\n",
    "\n",
    "\n",
    "print(text)\n",
    "# set up the client\n",
    "print('---')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner','depparse','coref'], timeout=150000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    \n",
    "#     lemma:/(cause|stimulate|make|derive|trigger|result|lead)/\n",
    "#     pattern = '{}=cause <nsubj ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >dobj {}=effect)'\n",
    "    pattern = \"{}=cause <nsubj ({lemma:/(cause|stimulate|make|derive|trigger|result|lead|incur|induce|decrease|increase|drive|stimulate|reduce|influence|effect|derive|affect)/}=trigger >dobj {}=effect!>neg{pos:RB})\"\n",
    "    \n",
    "    matches = client.semgrex(text, pattern)\n",
    "    print(\"------------------------\")\n",
    "    print(matches)\n",
    "    print(matches[\"sentences\"] == [{'length': 0}])\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing someone causes insomnia\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-5a22e5366c3641d5.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "[{'0': {'text': 'Missing', 'begin': 0, 'end': 1, '$cause': {'text': 'insomnia', 'begin': 3, 'end': 4}, '$subj': {'text': 'Missing', 'begin': 0, 'end': 1}, '$target': {'text': 'causes', 'begin': 2, 'end': 3}}, 'length': 1}]\n",
      "insomnia\n",
      "Missing\n",
      "causes\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "# text = \"Over thinking can increase anxiety and cause insomnia.\"\n",
    "text = \"Missing someone causes insomnia\"\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    ann = client.annotate(text)\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "    pattern = '{}=cause <csubj ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >dobj {}=effect)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "\n",
    "    print(matches[\"sentences\"])\n",
    "#     print(len(matches[\"sentences\"]))\n",
    "#     print(matches[\"sentences\"][0][\"length\"])\n",
    "\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'3 nevertheless, despite the availability of guideline recommendations,4–6 diagnostic confusion between copd and asthma appears common, and often it is very difficult in a patient with airway obstruction to decide whether the obstruction is caused by asthma or copd\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-8145bc65f7d84b91.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'obstruction', 'begin': 38, 'end': 39, '$effect': {'text': 'obstruction', 'begin': 38, 'end': 39}, '$cause': {'text': 'asthma', 'begin': 42, 'end': 43}, '$trigger': {'text': 'caused', 'begin': 40, 'end': 41}}, '1': {'text': 'obstruction', 'begin': 38, 'end': 39, '$effect': {'text': 'obstruction', 'begin': 38, 'end': 39}, '$cause': {'text': 'copd', 'begin': 44, 'end': 45}, '$trigger': {'text': 'caused', 'begin': 40, 'end': 41}}, 'length': 2}]}\n",
      "------------------------\n",
      "obstruction\n",
      "caused\n",
      "asthma\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "# text = \"My insomnia was caused by stress.\"\n",
    "# text = \"Stress was caused by insomnia\"\n",
    "text = \"3 another study,4 followed copd patients for 1 year, observed a high rate of exacerbations in one subgroup – 37% of these were caused by bacteria, 10% by viruses, 12% by bacteria and viruses, while 14% were of undefined origin\"\n",
    "\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "    \n",
    "    # Use semgrex patterns to directly find who wrote what.\n",
    "    pattern = '{}=effect <nsubjpass ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >/nmod:agent/ {}=cause)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stress is a reason of my insomnia\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-38f72783901847e2.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'Stress', 'begin': 0, 'end': 1, '$effect': {'text': 'insomnia', 'begin': 6, 'end': 7}, '$cause': {'text': 'Stress', 'begin': 0, 'end': 1}, '$trigger': {'text': 'reason', 'begin': 3, 'end': 4}}, 'length': 1}]}\n",
      "------------------------\n",
      "Stress\n",
      "reason\n",
      "insomnia\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "text = \"Stress is a reason of my insomnia\"\n",
    "# text = \"School is the main cause of my stress.\"\n",
    "# text = \"You're the cause of my headaches.\"\n",
    "\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    \n",
    "    pattern = \"{}=cause <nsubj ({lemma:/(reason|cause|trigger)/}=trigger >/nmod:of/ {}=effect !>neg {pos:RB})\"\n",
    "#     pattern = '{}=cause <nsubj ({lemma:/(reason|cause)/}=trigger >/nmod:of/ {}=effect)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insomnia is a result of stress\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-aaadb506e4ab45fa.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'Insomnia', 'begin': 0, 'end': 1, '$effect': {'text': 'Insomnia', 'begin': 0, 'end': 1}, '$cause': {'text': 'stress', 'begin': 5, 'end': 6}, '$trigger': {'text': 'result', 'begin': 3, 'end': 4}}, 'length': 1}]}\n",
      "------------------------\n",
      "stress\n",
      "result\n",
      "Insomnia\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "text = \"Insomnia is a result of stress\"\n",
    "# text = \"School is the main cause of my stress.\"\n",
    "# text = \"You're the cause of my headaches.\"\n",
    "\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    # Use semgrex patterns to directly find who wrote what.\n",
    "    pattern = '{}=effect <nsubj ({lemma:/(result|trigger)/}=trigger >/nmod:of/ {}=cause !>neg {pos:RB})'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insomnia was caused by overthinking\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-294eb5c3883640c4.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'Insomnia', 'begin': 0, 'end': 1, '$pcomp': {'text': 'overthinking', 'begin': 4, 'end': 5}, '$nsubj': {'text': 'Insomnia', 'begin': 0, 'end': 1}, '$target': {'text': 'caused', 'begin': 2, 'end': 3}}, 'length': 1}]}\n",
      "------------------------\n",
      "Insomnia\n",
      "caused\n",
      "overthinking\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "text = \"Insomnia was caused by overthinking\"\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "    \n",
    "    # Use semgrex patterns to directly find who wrote what.\n",
    "    pattern = '{}=effect <nsubjpass ({lemma:/(result|reason|cause)/}=trigger >/advcl:by/ {}=cause)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jones et al demonstrated that the presence of sarcopenia in copd affect the response to pr and in some patients pr might lead to a resolution of sarcopenia\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-1fb2467735424a48.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'pr', 'begin': 20, 'end': 21, '$effect': {'text': 'patients', 'begin': 19, 'end': 20}, '$cause': {'text': 'pr', 'begin': 20, 'end': 21}, '$trigger': {'text': 'lead', 'begin': 22, 'end': 23}}, '1': {'text': 'pr', 'begin': 20, 'end': 21, '$effect': {'text': 'resolution', 'begin': 25, 'end': 26}, '$cause': {'text': 'pr', 'begin': 20, 'end': 21}, '$trigger': {'text': 'lead', 'begin': 22, 'end': 23}}, 'length': 2}]}\n",
      "------------------------\n",
      "pr\n",
      "lead\n",
      "patients\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "# text = \"Stress results to insomnia.\"\n",
    "# text = \"Night before first day of school always results in insomnia.\"\n",
    "# text = \"Nervous Stressed Leads to swollen eye & headaches.\"   #추출 안됌\n",
    "# text = \"Too many tears leads to headaches and heavy hearts.\"\n",
    "# text = \"stress lead to depression\"\n",
    "# text = \"stress give rise to depression\"\n",
    "# text = 'stress gave rise to depression'\n",
    "# text = 'stress led to depression'\n",
    "# text = \"stress lead to increase insomnia\"\n",
    "\n",
    "\n",
    "\n",
    "# A Cochrane review65 suggested that a short course, 3 to 7days, of systemic corticosteroids does not lead to increase in treatment failure or risk of relapse of AECOPD\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "#     pattern = '{}=cause </(nsubj|csubj|subj|compound)/ ({lemma:/(cause|stimulate|make|derive|trigger|result|lead|give)/}=trigger >/nmod:(to|in)/ {}=effect)'\n",
    "    pattern = '{}=cause </(nsubj|csubj|subj|compound)/ ({lemma:/(cause|stimulate|make|derive|trigger|result|lead|incur|induce|decrease|increase|drive|stimulate|reduce|influence|effect|derive)/}=trigger >/nmod:(to|in)/ !{pos:CD}=effect !>neg {pos:RB})'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depression results from stress\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-fbca2de3bb034cdd.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'depression', 'begin': 0, 'end': 1, '$cause': {'text': 'depression', 'begin': 0, 'end': 1}, '$causal': {'text': 'stress', 'begin': 3, 'end': 4}, '$target': {'text': 'results', 'begin': 1, 'end': 2}}, 'length': 1}]}\n",
      "------------------------\n",
      "stress\n",
      "results\n",
      "depression\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "# text= \"depression resulted from stress\"\n",
    "text = 'depression results from stress'\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    pattern = '{}=effect </(nsubj|csubj|subj|compound)/ ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >/nmod:from/ {}=cause)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of sirt1 correlates with tissue inhibitor of metalloproteinase -1 lysine acetylation and subsequent degradation of timp-1, the major anti-mmp protease, resulting in increased mmp-9 in human copd lung tissue\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-7b131156dc7e4a84.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'inhibitor', 'begin': 6, 'end': 7, '$effect': {'text': 'mmp-9', 'begin': 26, 'end': 27}, '$cause': {'text': 'inhibitor', 'begin': 6, 'end': 7}, '$trigger': {'text': 'resulting', 'begin': 23, 'end': 24}}, 'length': 1}]}\n",
      "------------------------\n",
      "inhibitor\n",
      "resulting\n",
      "mmp-9\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "# text= \"stress leading to depression\"\n",
    "# text = \"this in turn promotes airway and systemic infiammation leading to copd progression\"\n",
    "\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    pattern = '{}=cause >acl ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >/nmod:(to|in)/ {}=effect)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "systemic lead to treatment failure\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-f9de9de2d3de4e35.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'length': 0}]}\n",
      "------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x3/lny9bbwx64b561c29r4y4z400000gn/T/ipykernel_88773/505542553.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"$cause\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"$trigger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"$effect\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "text= \"stress giving rise to depression\"\n",
    "\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    pattern = '{}=cause >acl ({lemma:/give/}=trigger >/nmod:(to|in)/ {}=effect)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule10(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the reason of insomnia is stress\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-bcb76ce3fd304ae5.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'stress', 'begin': 5, 'end': 6, '$be': {'text': 'is', 'begin': 4, 'end': 5}, '$effect': {'text': 'insomnia', 'begin': 3, 'end': 4}, '$cause': {'text': 'stress', 'begin': 5, 'end': 6}, '$trigger': {'text': 'reason', 'begin': 1, 'end': 2}}, 'length': 1}]}\n",
      "------------------------\n",
      "stress\n",
      "insomnia\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "#the reason(s) for/of B BE\n",
    "\n",
    "# text= \"the reason for insomnia is stress\"\n",
    "text= \"the reason of insomnia is stress\"\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    pattern = \"{}=cause !>neg{pos:RB} >cop {lemma:/(be)/}=be >nsubj ({lemma:/(reason)/}=trigger >/nmod:(for|of)/ {}=effect)\"\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "#     print(matches[\"sentences\"][0][\"0\"][\"$be\"][\"text\"])\n",
    "#     print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule11(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result of stress is insomnia\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-3ff8bd77cd264dd7.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'insomnia', 'begin': 5, 'end': 6, '$be': {'text': 'is', 'begin': 4, 'end': 5}, '$effect': {'text': 'insomnia', 'begin': 5, 'end': 6}, '$cause': {'text': 'stress', 'begin': 3, 'end': 4}, '$trigger': {'text': 'result', 'begin': 1, 'end': 2}}, 'length': 1}]}\n",
      "------------------------\n",
      "stress\n",
      "is\n",
      "result\n",
      "insomnia\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "#DET effect of A BE B\n",
    "\n",
    "text= \"the result of stress is insomnia\"\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    pattern = '{}=effect !>neg{pos:RB} >cop {lemma:/(be)/}=be >nsubj ({lemma:/(result)/}=trigger >/nmod:(of)/ {}=cause)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$be\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule12(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stress is a reason for insomnia\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-82c4bb9f106e47b4.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'reason', 'begin': 3, 'end': 4, '$be': {'text': 'is', 'begin': 1, 'end': 2}, '$effect': {'text': 'insomnia', 'begin': 5, 'end': 6}, '$cause': {'text': 'Stress', 'begin': 0, 'end': 1}, '$trigger': {'text': 'reason', 'begin': 3, 'end': 4}}, 'length': 1}]}\n",
      "------------------------\n",
      "Stress\n",
      "is\n",
      "reason\n",
      "insomnia\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "#A BE DET reason(s) for B\n",
    "text= \"Stress is a reason for insomnia\"\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "    pattern = '{lemma:/reason/}=trigger >nsubj {}=cause >/nmod:(of|for)/ {}=effect >cop {lemma:/be/}=be !>neg{pos:RB}'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$be\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule13(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stress brings on insomnia\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-01a56ff9e1ff4039.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'brings', 'begin': 1, 'end': 2, '$effect': {'text': 'insomnia', 'begin': 3, 'end': 4}, '$cause': {'text': 'stress', 'begin': 0, 'end': 1}, '$trigger': {'text': 'brings', 'begin': 1, 'end': 2}}, 'length': 1}]}\n",
      "------------------------\n",
      "stress\n",
      "insomnia\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "#A brings on B\n",
    "text= \"stress brings on insomnia\"\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "    pattern = '{lemma:/bring/}=trigger >nsubj {}=cause >/(nmod:on|dobj)/{}=effect !>neg{pos:RB}'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "#     print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule14(진행중. Rule5랑 비슷한데 왜 안되는지 모르겠음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stress caused by insomnia\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-993c24b2234f439f.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'length': 0}]}\n",
      "------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x3/lny9bbwx64b561c29r4y4z400000gn/T/ipykernel_48707/1118437028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"$cause\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"$trigger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"$effect\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "#A brings on B\n",
    "text= \"stress caused by insomnia\"\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "    pattern = '{}=effect <nsubj ({lemma:/(cause)/}=trigger >/advcl:by/ {}=cause)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jones et al demonstrated that the presence of sarcopenia in copd does affect the response to pr and in some patients pr might lead to a resolution of sarcopenia\n",
      "---------------------------------------------\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-db2805f65a594ef7.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---------------------------------------------\n",
      "{'sentences': [{'0': {'text': 'affect', 'begin': 12, 'end': 13, '$effect': {'text': 'response', 'begin': 14, 'end': 15}, '$cause': {'text': 'sarcopenia', 'begin': 28, 'end': 29}, '$trigger': {'text': 'affect', 'begin': 12, 'end': 13}}, '1': {'text': 'affect', 'begin': 12, 'end': 13, '$effect': {'text': 'response', 'begin': 14, 'end': 15}, '$cause': {'text': 'sarcopenia', 'begin': 8, 'end': 9}, '$trigger': {'text': 'affect', 'begin': 12, 'end': 13}}, 'length': 2}]}\n",
      "------------------------\n",
      "sarcopenia\n",
      "response\n",
      "affect\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "#A brings on B\n",
    "text= \"jones et al demonstrated that the presence of sarcopenia in copd does affect the response to pr and in some patients pr might lead to a resolution of sarcopenia\"\n",
    "\n",
    "print(text)\n",
    "\n",
    "# set up the client\n",
    "print('---------------------------------------------')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    # get the first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "    pattern = '{lemma:/(cause|stimulate|make|derive|trigger|result|lead|incur|induce|decrease|increase|drive|stimulate|reduce|influence|effect|derive|affect)/}=trigger >>/nmod:of/{}=cause >dobj{}=effect !>neg{pos:RB}'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    \n",
    "    print(matches)\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "#     print(matches[\"sentences\"][0][\"0\"][\"$be\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stress doesn't cause depression\n",
      "---\n",
      "starting up Java Stanford CoreNLP Server...\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 150000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-3afbe00a2ede4faa.props -preload tokenize,ssplit,pos,lemma,ner,depparse,coref\n",
      "------------------------\n",
      "{'sentences': [{'0': {'text': 'stress', 'begin': 0, 'end': 1, '$not': {'text': \"n't\", 'begin': 2, 'end': 3}, '$effect': {'text': 'depression', 'begin': 4, 'end': 5}, '$cause': {'text': 'stress', 'begin': 0, 'end': 1}, '$trigger': {'text': 'cause', 'begin': 3, 'end': 4}}, 'length': 1}]}\n",
      "False\n",
      "------------------------\n",
      "stress\n",
      "cause\n",
      "depression\n",
      "n't\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "# text = \"Stress causes insomnia.\"\n",
    "# text = \"Missing someone causes insomnia.\"  #Missing someone으로 추출이 안되네?\n",
    "# text = \"Money only causes stress and conflict.\"\n",
    "# text = \"Cell phone radiation can cause insomnia\"\n",
    "# text = \"My neck just made my headache 100x worse.\"  # >dobj로 하면 추출 안됨 패턴 바꿔야함\n",
    "text = \"stress doesn't cause depression\" \n",
    "\n",
    "# {pos:/VB.*/}\n",
    "# {pos:/NN.*/}\n",
    "\n",
    "print(text)\n",
    "# set up the client\n",
    "print('---')\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner','depparse','coref'], timeout=150000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    \n",
    "#     lemma:/(cause|stimulate|make|derive|trigger|result|lead)/\n",
    "    pattern = '{}=cause <nsubj ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >dobj {}=effect >neg {pos:/RB.*/}=not)'\n",
    "    matches = client.semgrex(text, pattern)\n",
    "    print(\"------------------------\")\n",
    "    print(matches)\n",
    "    print(matches[\"sentences\"] == [{'length': 0}])\n",
    "    print(\"------------------------\")\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"])\n",
    "    print(matches[\"sentences\"][0][\"0\"][\"$not\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causality Extraction(cause, effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' insomnia', ' “Stress caused insomnia”', ' “Stress results in insomnia”', ' “Stress was caused by insomnia”', ' such as “Stress caused my insomnia”', ' where “Stress” is matched with the pattern “{} = subj” and “insomnia” is matched with the pattern “{} = cause', ' insomnia', ' Stress causes insomnia A ', ' Examples Over thinking can increase anxiety and cause insomnia', ' My insomnia was caused by stress', ' Stress is a reason of my insomnia {} = nsubj< nsubjpass ', ' Stress results to insomnia', ' 72 out of 3827 for insomnia ', ' The final causalities extracted were 41 for insomnia', ' similar phrases “missing someone causes insomnia”', ' “missing someone often causes insomnia”', ' and “missing someone causes insomnia like symptoms” were found', ' “Cell phone radiation can cause insomnia”', ' It also indicates that finding causal relationships for “headache” is more difficult than “insomnia” and “stress”', '27% Total # extracted causalities Qualitative analysis We further manually analyzed the causes of insomnia', ' Insomnia We found that the most frequent cause related to insomnia was “missing someone”', ' Missing someone causes insomnia', 'insomnia/NN Night before first day of school always results in insomnia', 'insomnia/NN Stress Frequent topics related to stress for Twitter users include school', ' such as “Could this be the cause of my insomnia?”', ' such as “I wouldn’t say it causes insomnia though”', ' “can’t sleep” as a synonymous expression of “insomnia']\n"
     ]
    }
   ],
   "source": [
    "txt = open(\"pattern_test.txt\", \"r\")\n",
    "slist2=txt.read()\n",
    "slist2 = slist2.replace(\"(\",\".\")\n",
    "slist2 = slist2.replace(\")\",\".\")\n",
    "slist2 = slist2.replace(\"[\",\".\")\n",
    "slist2 = slist2.replace(\"]\",\".\")\n",
    "slist2 = slist2.replace(\";\",\".\")\n",
    "slist2 = slist2.replace(\":\",\".\")\n",
    "slist2 = slist2.replace(\",\",\".\")\n",
    "# 쉼표(,)를 split안해주려고 했는데 이거 안하면 문장이 엄청 길어져서 패턴6에 걸치게됨\n",
    "slist2 = slist2.split(\".\")\n",
    "slist2 = list(filter(None, slist2))\n",
    "\n",
    "def func1(n):\n",
    "    if n == \" \":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "slist2 = list(filter(func1, slist2))\n",
    "dlist=[]\n",
    "for s in slist2:\n",
    "#     if (\"Depression\" or \"depression\") in s:\n",
    "    if (\"insomnia\" or \"stress\" or \"headache\") in s:\n",
    "        dlist.append(s)\n",
    "\n",
    "print(dlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Starting server with command: java -Xmx16G -cp /Users/kyle/stanford-corenlp-full-2018-10-05//* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 200000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-dea1caf532c0498c.props -preload tokenize,ssplit,pos,lemma,ner,depparse,coref\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "# slist = [\"Stress causes insomnia.\", \"Missing someone causes insomnia.\", \"Money only causes stress and conflict.\", \"My neck just made my headache 100x worse.\", \"Over thinking can increase anxiety and cause insomnia.\"]\n",
    "plist = ['{}=cause <nsubj ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >dobj {}=effect)', '{}=cause <csubj ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >dobj {}=effect)', '{}=effect <nsubjpass ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >/nmod:agent/ {}=cause)', '{}=cause <nsubj ({lemma:/(result|reason|cause)/}=trigger >/nmod:of/ {}=effect)', '{}=effect <nsubjpass ({lemma:/(result|reason|cause)/}=trigger >/advcl:by/ {}=cause)', '{}=cause </(nsubj|csubj|subj|compound)/ ({lemma:/(cause|stimulate|make|derive|trigger|result|lead|give)/}=trigger >/nmod:(to|in)/ {}=effect)', '{}=effect </(nsubj|csubj|subj|compound)/ ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >/nmod:from/ {}=cause)', '{}=cause >acl ({lemma:/(cause|stimulate|make|derive|trigger|result|lead)/}=trigger >/nmod:(to|in)/ {}=effect)', '{}=cause >acl ({lemma:/give/}=trigger >/nmod:(to|in)/ {}=effect)']\n",
    "clist = [] #cause list\n",
    "elist = [] #effect list\n",
    "tlist = [] #trigger list\n",
    "\n",
    "dlist = [\"A Cochrane review65 suggested that a short course, 3 to 7days, of systemic corticosteroids does not lead to increase in treatment failure or risk of relapse of AECOPD.\"]\n",
    "\n",
    "for i, text in enumerate(dlist):\n",
    "    print(i+1)\n",
    "    with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner','depparse','coref'], timeout=200000, memory='16G') as client:\n",
    "        ann = client.annotate(text)\n",
    "        \n",
    "        for p, pattern in enumerate(plist):\n",
    "            matches = client.semgrex(text, pattern)\n",
    "            if (matches[\"sentences\"][0] == {'length': 0}):\n",
    "                next\n",
    "            else:\n",
    "                clist.append({text + \" / pattern: \" + str(p+1) : matches[\"sentences\"][0][\"0\"][\"$cause\"][\"text\"]})\n",
    "                elist.append({text + \" / pattern: \" + str(p+1) : matches[\"sentences\"][0][\"0\"][\"$effect\"][\"text\"]})\n",
    "                tlist.append({text + \" / pattern: \" + str(p+1) : matches[\"sentences\"][0][\"0\"][\"$trigger\"][\"text\"]})\n",
    "                \n",
    "# print('---------------')\n",
    "# print(\" \")\n",
    "# for i in clist:\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cause\n",
    "for i in clist:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Effect\n",
    "for i in elist:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trigger\n",
    "for i in tlist:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "201px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
